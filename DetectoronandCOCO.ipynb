{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f767b171-d977-4fb7-a34f-534277c9cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b532c8e2-a6db-457d-aee0-dc2421ae14fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "image_path = 'Woman_at_Beach.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "# Create a Detectron 2 configuration\n",
    "cfg = get_cfg()\n",
    "\n",
    "#to fetch a specific configuration file for a model we get the yaml file\n",
    "#object detection, image classification, segmentation, etc. A model zoo helps practitioners-- \n",
    "# -- and researchers by providing them with models that have already been trained and mergers it with current congiguration\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "#MODEL.ROI_HEADS.SCORE_THRESH_TEST is a configuration parameter commonly used in object detection frameworks like Detectron2\n",
    "#ROI_HEADS: Region of Interest (RoI) threshold\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4  # Set a confidence threshold for detections\n",
    "cfg.MODEL.DEVICE = 'cpu'  # Use CPU for inference\n",
    "\n",
    "# Load the pre-trained Detectron 2 model\n",
    "# give the URL to the model.weighs\n",
    "#weights associated with the neural network layers, bounding box regression, and object classification\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Perform object detection\n",
    "outputs = predictor(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dcdd9-8bea-453d-b45a-a7357cf3e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "# image[:, :, ::-1] makes RGB, BGR\n",
    "# MetadataCatalog is a utility class that provides access to metadata associated with datasets used for object detection and instance segmentation\n",
    "v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow(\"Object Detection\", out.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11216df-5ffa-4594-a46f-7a893ae78398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb71a86-bab3-43c2-9ca7-207377346761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Thing Classes: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "image_path = 'Woman_at_Beach.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Create a Detectron 2 configuration\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load a specific configuration file for a model (faster R-CNN in this case)\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Set a confidence threshold for detections\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "cfg.MODEL.DEVICE = 'cpu'  # Use CPU for inference\n",
    "\n",
    "# Load the pre-trained Detectron 2 model weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Perform object detection\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Print available thing classes\n",
    "print(\"Available Thing Classes:\", MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92711f03-5a32-4c29-b39d-b77ef14f8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get instances from the outputs\n",
    "instances = outputs[\"instances\"].to(\"cpu\")\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "\n",
    "# Get class IDs for hat and houses\n",
    "#hat_class_id = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(\"hat\")\n",
    "boat_class_id = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(\"boat\")\n",
    "\n",
    "# Choose the correct class names for hat and houses based on the printed list\n",
    "#hat_class_name = \"person\"  # Replace with the correct class name for the hat\n",
    "boat_class_name = \"boat\"  # Replace with the correct class name for boats\n",
    "\n",
    "# Get class IDs for hat and houses\n",
    "#hat_class_id = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(hat_class_name)\n",
    "boat_class_id = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(boat_class_name)\n",
    "\n",
    "# Filter instances for hat and boats\n",
    "#hat_instances = instances[instances.pred_classes == hat_class_id]\n",
    "boat_instances = instances[instances.pred_classes == boat_class_id]\n",
    "\n",
    "# Visualize the results for hat\n",
    "#v_hat = Visualizer(image[:, :, ::-1], metadata, scale=0.2)\n",
    "#out_hat = v_hat.draw_instance_predictions(hat_instances)\n",
    "#cv2.imshow(\"Hat Detection\", out_hat.get_image()[:, :, ::-1])\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Visualize the results for boats\n",
    "v_boats = Visualizer(image[:, :, ::-1], metadata, scale=1.2)\n",
    "out_boats = v_boats.draw_instance_predictions(boat_instances)\n",
    "cv2.imshow(\"Boats Detection\", out_boats.get_image()[:, :, ::-1])\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "# Wait for 30 seconds (300000 milliseconds)\n",
    "cv2.waitKey(15)\n",
    "\n",
    "# Close the window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8dbf0-77ca-4fb8-ba99-e4bc8835c1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
